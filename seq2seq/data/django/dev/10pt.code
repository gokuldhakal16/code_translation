from threading import local
 import warnings
  from django . conf import settings
 from django . core import signals
 from django . core . cache . backends . base import (  InvalidCacheBackendError , CacheKeyWarning , BaseCache )
 from django . core . exceptions import ImproperlyConfigured
 from django . utils . deprecation import RemovedInDjango19Warning
 from django . utils . module_loading import import_string
   __all__ = [  'get_cache' , 'cache' , 'DEFAULT_CACHE_ALIAS' , 'InvalidCacheBackendError' ,  'CacheKeyWarning' , 'BaseCache' ,  ]
  DEFAULT_CACHE_ALIAS = 'default'
  if DEFAULT_CACHE_ALIAS not in settings . CACHES :
      raise ImproperlyConfigured ( "You must define a '%s' cache" % DEFAULT_CACHE_ALIAS )
    def get_cache ( backend , ** kwargs ) :
 warnings . warn ( "'get_cache' is deprecated in favor of 'caches'." ,  RemovedInDjango19Warning , stacklevel = 2 )
 cache = _create_cache ( backend , ** kwargs )
    signals . request_finished . connect ( cache . close )
 return cache
    def _create_cache ( backend , ** kwargs ) :
      try :
           try :
              conf = settings . CACHES [ backend ]
  except KeyError :
              try :
                   import_string ( backend )
  except ImportError as e :
                  raise InvalidCacheBackendError ( "Could not find backend '%s': %s" % (  backend , e ) )
  location = kwargs . pop ( 'LOCATION' , '' )
 params = kwargs
  else :
              params = conf . copy ( )
 params . update ( kwargs )
 backend = params . pop ( 'BACKEND' )
 location = params . pop ( 'LOCATION' , '' )
  backend_cls = import_string ( backend )
  except ImportError as e :
          raise InvalidCacheBackendError (  "Could not find backend '%s': %s" % ( backend , e ) )
  return backend_cls ( location , params )
    class CacheHandler ( object ) :
 def __init__ ( self ) :
          self . _caches = local ( )
   def __getitem__ ( self , alias ) :
          try :
              return self . _caches . caches [ alias ]
  except AttributeError :
              self . _caches . caches = { }
  except KeyError :
              pass
   if alias not in settings . CACHES :
              raise InvalidCacheBackendError (  "Could not find config for '%s' in settings.CACHES" % alias  )
   cache = _create_cache ( alias )
 self . _caches . caches [ alias ] = cache
 return cache
   def all ( self ) :
          return getattr ( self . _caches , 'caches' , { } ) . values ( )
    caches = CacheHandler ( )
   class DefaultCacheProxy ( object ) :
 def __getattr__ ( self , name ) :
          return getattr ( caches [ DEFAULT_CACHE_ALIAS ] , name )
   def __setattr__ ( self , name , value ) :
          return setattr ( caches [ DEFAULT_CACHE_ALIAS ] , name , value )
   def __delattr__ ( self , name ) :
          return delattr ( caches [ DEFAULT_CACHE_ALIAS ] , name )
   def __contains__ ( self , key ) :
          return key in caches [ DEFAULT_CACHE_ALIAS ]
   def __eq__ ( self , other ) :
          return caches [ DEFAULT_CACHE_ALIAS ] == other
   def __ne__ ( self , other ) :
          return caches [ DEFAULT_CACHE_ALIAS ] != other
    cache = DefaultCacheProxy ( )
   def close_caches ( ** kwargs ) :
         for cache in caches . all ( ) :
          cache . close ( )
   signals . request_finished . connect ( close_caches )
 from __future__ import unicode_literals
  import time
 import warnings
  from django . core . exceptions import ImproperlyConfigured , DjangoRuntimeWarning
 from django . utils . module_loading import import_string
   class InvalidCacheBackendError ( ImproperlyConfigured ) :
      pass
    class CacheKeyWarning ( DjangoRuntimeWarning ) :
      pass
      DEFAULT_TIMEOUT = object ( )
   MEMCACHE_MAX_KEY_LENGTH = 250
   def default_key_func ( key , key_prefix , version ) :
 return '%s:%s:%s' % ( key_prefix , version , key )
    def get_key_func ( key_func ) :
 if key_func is not None :
          if callable ( key_func ) :
              return key_func
  else :
              return import_string ( key_func )
   return default_key_func
    class BaseCache ( object ) :
      def __init__ ( self , params ) :
          timeout = params . get ( 'timeout' , params . get ( 'TIMEOUT' , 300 ) )
 if timeout is not None :
              try :
                  timeout = int ( timeout )
  except ( ValueError , TypeError ) :
                  timeout = 300
   self . default_timeout = timeout
  options = params . get ( 'OPTIONS' , { } )
 max_entries = params . get ( 'max_entries' , options . get ( 'MAX_ENTRIES' , 300 ) )
 try :
              self . _max_entries = int ( max_entries )
  except ( ValueError , TypeError ) :
              self . _max_entries = 300
   cull_frequency = params . get ( 'cull_frequency' , options . get ( 'CULL_FREQUENCY' , 3 ) )
 try :
              self . _cull_frequency = int ( cull_frequency )
  except ( ValueError , TypeError ) :
              self . _cull_frequency = 3
   self . key_prefix = params . get ( 'KEY_PREFIX' , '' )
 self . version = params . get ( 'VERSION' , 1 )
 self . key_func = get_key_func ( params . get ( 'KEY_FUNCTION' , None ) )
   def get_backend_timeout ( self , timeout = DEFAULT_TIMEOUT ) :
 if timeout == DEFAULT_TIMEOUT :
              timeout = self . default_timeout
  elif timeout == 0 :
               timeout = - 1
  return None if timeout is None else time . time ( ) + timeout
   def make_key ( self , key , version = None ) :
 if version is None :
              version = self . version
   new_key = self . key_func ( key , self . key_prefix , version )
 return new_key
   def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          """         Set a value in the cache if the key does not already exist. If         timeout is given, that timeout will be used for the key; otherwise         the default cache timeout will be used.         Returns True if the value was stored, False otherwise.         """
 raise NotImplementedError ( 'subclasses of BaseCache must provide an add() method' )
   def get ( self , key , default = None , version = None ) :
 raise NotImplementedError ( 'subclasses of BaseCache must provide a get() method' )
   def set ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
 raise NotImplementedError ( 'subclasses of BaseCache must provide a set() method' )
   def delete ( self , key , version = None ) :
 raise NotImplementedError ( 'subclasses of BaseCache must provide a delete() method' )
   def get_many ( self , keys , version = None ) :
 d = { }
 for k in keys :
              val = self . get ( k , version = version )
 if val is not None :
                  d [ k ] = val
   return d
   def has_key ( self , key , version = None ) :
 return self . get ( key , version = version ) is not None
   def incr ( self , key , delta = 1 , version = None ) :
 value = self . get ( key , version = version )
 if value is None :
              raise ValueError ( "Key '%s' not found" % key )
  new_value = value + delta
 self . set ( key , new_value , version = version )
 return new_value
   def decr ( self , key , delta = 1 , version = None ) :
 return self . incr ( key , - delta , version = version )
   def __contains__ ( self , key ) :
    return self . has_key ( key )
   def set_many ( self , data , timeout = DEFAULT_TIMEOUT , version = None ) :
 for key , value in data . items ( ) :
              self . set ( key , value , timeout = timeout , version = version )
    def delete_many ( self , keys , version = None ) :
 for key in keys :
              self . delete ( key , version = version )
    def clear ( self ) :
 raise NotImplementedError ( 'subclasses of BaseCache must provide a clear() method' )
   def validate_key ( self , key ) :
 if len ( key ) > MEMCACHE_MAX_KEY_LENGTH :
              warnings . warn ( 'Cache key will cause errors if used with memcached: '  '%s (longer than %s)' % ( key , MEMCACHE_MAX_KEY_LENGTH ) ,  CacheKeyWarning )
  for char in key :
              if ord ( char ) < 33 or ord ( char ) == 127 :
                  warnings . warn ( 'Cache key contains characters that will cause '  'errors if used with memcached: %r' % key ,  CacheKeyWarning )
     def incr_version ( self , key , delta = 1 , version = None ) :
 if version is None :
              version = self . version
   value = self . get ( key , version = version )
 if value is None :
              raise ValueError ( "Key '%s' not found" % key )
   self . set ( key , value , version = version + delta )
 self . delete ( key , version = version )
 return version + delta
   def decr_version ( self , key , delta = 1 , version = None ) :
 return self . incr_version ( key , - delta , version )
   def close ( self , ** kwargs ) :
          """Close the cache connection"""
 pass
 import base64
 from datetime import datetime
  try :
      from django . utils . six . moves import cPickle as pickle
  except ImportError :
      import pickle
   from django . conf import settings
 from django . core . cache . backends . base import BaseCache , DEFAULT_TIMEOUT
 from django . db import connections , transaction , router , DatabaseError
 from django . db . backends . utils import typecast_timestamp
 from django . utils import timezone , six
 from django . utils . encoding import force_bytes
   class Options ( object ) :
 def __init__ ( self , table ) :
          self . db_table = table
 self . app_label = 'django_cache'
 self . model_name = 'cacheentry'
 self . verbose_name = 'cache entry'
 self . verbose_name_plural = 'cache entries'
 self . object_name = 'CacheEntry'
 self . abstract = False
 self . managed = True
 self . proxy = False
     class BaseDatabaseCache ( BaseCache ) :
      def __init__ ( self , table , params ) :
          BaseCache . __init__ ( self , params )
 self . _table = table
  class CacheEntry ( object ) :
              _meta = Options ( table )
  self . cache_model_class = CacheEntry
     class DatabaseCache ( BaseDatabaseCache ) :
                 def get ( self , key , default = None , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 db = router . db_for_read ( self . cache_model_class )
 table = connections [ db ] . ops . quote_name ( self . _table )
  with connections [ db ] . cursor ( ) as cursor :
              cursor . execute ( "SELECT cache_key, value, expires FROM %s "  "WHERE cache_key = %%s" % table , [ key ] )
 row = cursor . fetchone ( )
  if row is None :
              return default
  now = timezone . now ( )
 expires = row [ 2 ]
 if connections [ db ] . features . needs_datetime_string_cast and not isinstance ( expires , datetime ) :
                 expires = typecast_timestamp ( str ( expires ) )
  if expires < now :
              db = router . db_for_write ( self . cache_model_class )
 with connections [ db ] . cursor ( ) as cursor :
                  cursor . execute ( "DELETE FROM %s "  "WHERE cache_key = %%s" % table , [ key ] )
  return default
  value = connections [ db ] . ops . process_clob ( row [ 1 ] )
 return pickle . loads ( base64 . b64decode ( force_bytes ( value ) ) )
   def set ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 self . _base_set ( 'set' , key , value , timeout )
   def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 return self . _base_set ( 'add' , key , value , timeout )
   def _base_set ( self , mode , key , value , timeout = DEFAULT_TIMEOUT ) :
          timeout = self . get_backend_timeout ( timeout )
 db = router . db_for_write ( self . cache_model_class )
 table = connections [ db ] . ops . quote_name ( self . _table )
  with connections [ db ] . cursor ( ) as cursor :
              cursor . execute ( "SELECT COUNT(*) FROM %s" % table )
 num = cursor . fetchone ( ) [ 0 ]
 now = timezone . now ( )
 now = now . replace ( microsecond = 0 )
 if timeout is None :
                  exp = datetime . max
  elif settings . USE_TZ :
                  exp = datetime . utcfromtimestamp ( timeout )
  else :
                  exp = datetime . fromtimestamp ( timeout )
  exp = exp . replace ( microsecond = 0 )
 if num > self . _max_entries :
                  self . _cull ( db , cursor , now )
  pickled = pickle . dumps ( value , pickle . HIGHEST_PROTOCOL )
 b64encoded = base64 . b64encode ( pickled )
   if six . PY3 :
                  b64encoded = b64encoded . decode ( 'latin1' )
  try :
                      with transaction . atomic ( using = db ) :
                      cursor . execute ( "SELECT cache_key, expires FROM %s "  "WHERE cache_key = %%s" % table , [ key ] )
 result = cursor . fetchone ( )
 if result :
                          current_expires = result [ 1 ]
 if ( connections [ db ] . features . needs_datetime_string_cast and not  isinstance ( current_expires , datetime ) ) :
                              current_expires = typecast_timestamp ( str ( current_expires ) )
   exp = connections [ db ] . ops . value_to_db_datetime ( exp )
 if result and ( mode == 'set' or ( mode == 'add' and current_expires < now ) ) :
                          cursor . execute ( "UPDATE %s SET value = %%s, expires = %%s "  "WHERE cache_key = %%s" % table ,  [ b64encoded , exp , key ] )
  else :
                          cursor . execute ( "INSERT INTO %s (cache_key, value, expires) "  "VALUES (%%s, %%s, %%s)" % table ,  [ key , b64encoded , exp ] )
    except DatabaseError :
                   return False
  else :
                  return True
     def delete ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
  db = router . db_for_write ( self . cache_model_class )
 table = connections [ db ] . ops . quote_name ( self . _table )
  with connections [ db ] . cursor ( ) as cursor :
              cursor . execute ( "DELETE FROM %s WHERE cache_key = %%s" % table , [ key ] )
    def has_key ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
  db = router . db_for_read ( self . cache_model_class )
 table = connections [ db ] . ops . quote_name ( self . _table )
  if settings . USE_TZ :
              now = datetime . utcnow ( )
  else :
              now = datetime . now ( )
  now = now . replace ( microsecond = 0 )
  with connections [ db ] . cursor ( ) as cursor :
              cursor . execute ( "SELECT cache_key FROM %s "  "WHERE cache_key = %%s and expires > %%s" % table ,  [ key , connections [ db ] . ops . value_to_db_datetime ( now ) ] )
 return cursor . fetchone ( ) is not None
    def _cull ( self , db , cursor , now ) :
          if self . _cull_frequency == 0 :
              self . clear ( )
  else :
               now = now . replace ( tzinfo = None )
 table = connections [ db ] . ops . quote_name ( self . _table )
 cursor . execute ( "DELETE FROM %s WHERE expires < %%s" % table ,  [ connections [ db ] . ops . value_to_db_datetime ( now ) ] )
 cursor . execute ( "SELECT COUNT(*) FROM %s" % table )
 num = cursor . fetchone ( ) [ 0 ]
 if num > self . _max_entries :
                  cull_num = num // self . _cull_frequency
 cursor . execute (  connections [ db ] . ops . cache_key_culling_sql ( ) % table ,  [ cull_num ] )
 cursor . execute ( "DELETE FROM %s "  "WHERE cache_key < %%s" % table ,  [ cursor . fetchone ( ) [ 0 ] ] )
     def clear ( self ) :
          db = router . db_for_write ( self . cache_model_class )
 table = connections [ db ] . ops . quote_name ( self . _table )
 with connections [ db ] . cursor ( ) as cursor :
              cursor . execute ( 'DELETE FROM %s' % table )
      class CacheClass ( DatabaseCache ) :
      pass
  from django . core . cache . backends . base import BaseCache , DEFAULT_TIMEOUT
   class DummyCache ( BaseCache ) :
      def __init__ ( self , host , * args , ** kwargs ) :
          BaseCache . __init__ ( self , * args , ** kwargs )
   def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 return True
   def get ( self , key , default = None , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 return default
   def set ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
   def delete ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
   def get_many ( self , keys , version = None ) :
          return { }
   def has_key ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 return False
   def set_many ( self , data , timeout = DEFAULT_TIMEOUT , version = None ) :
          pass
   def delete_many ( self , keys , version = None ) :
          pass
   def clear ( self ) :
          pass
      class CacheClass ( DummyCache ) :
      pass
 import errno
 import glob
 import hashlib
 import io
 import os
 import random
 import tempfile
 import time
 import zlib
 from django . core . cache . backends . base import BaseCache , DEFAULT_TIMEOUT
 from django . core . files . move import file_move_safe
 from django . utils . encoding import force_bytes
 try :
      from django . utils . six . moves import cPickle as pickle
  except ImportError :
      import pickle
    class FileBasedCache ( BaseCache ) :
      cache_suffix = '.djcache'
  def __init__ ( self , dir , params ) :
          super ( FileBasedCache , self ) . __init__ ( params )
 self . _dir = os . path . abspath ( dir )
 self . _createdir ( )
   def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          if self . has_key ( key , version ) :
              return False
  self . set ( key , value , timeout , version )
 return True
   def get ( self , key , default = None , version = None ) :
          fname = self . _key_to_file ( key , version )
 if os . path . exists ( fname ) :
              try :
                  with io . open ( fname , 'rb' ) as f :
                      if not self . _is_expired ( f ) :
                          return pickle . loads ( zlib . decompress ( f . read ( ) ) )
    except IOError as e :
                  if e . errno == errno . ENOENT :
                      pass
    return default
   def set ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          self . _createdir ( )
 fname = self . _key_to_file ( key , version )
 self . _cull ( )
 fd , tmp_path = tempfile . mkstemp ( dir = self . _dir )
 renamed = False
 try :
              with io . open ( fd , 'wb' ) as f :
                  expiry = self . get_backend_timeout ( timeout )
 f . write ( pickle . dumps ( expiry , - 1 ) )
 f . write ( zlib . compress ( pickle . dumps ( value ) , - 1 ) )
  file_move_safe ( tmp_path , fname , allow_overwrite = True )
 renamed = True
  finally :
              if not renamed :
                  os . remove ( tmp_path )
     def delete ( self , key , version = None ) :
          self . _delete ( self . _key_to_file ( key , version ) )
   def _delete ( self , fname ) :
          if not fname . startswith ( self . _dir ) or not os . path . exists ( fname ) :
              return
  try :
              os . remove ( fname )
  except OSError as e :
                if e . errno != errno . ENOENT :
                  raise
     def has_key ( self , key , version = None ) :
          fname = self . _key_to_file ( key , version )
 if os . path . exists ( fname ) :
              with io . open ( fname , 'rb' ) as f :
                  return not self . _is_expired ( f )
   return False
   def _cull ( self ) :
 filelist = self . _list_cache_files ( )
 num_entries = len ( filelist )
 if num_entries < self . _max_entries :
              return
  if self . _cull_frequency == 0 :
              return self . clear ( )
   filelist = random . sample ( filelist ,  int ( num_entries / self . _cull_frequency ) )
 for fname in filelist :
              self . _delete ( fname )
    def _createdir ( self ) :
          if not os . path . exists ( self . _dir ) :
              try :
                  os . makedirs ( self . _dir , 0o700 )
  except OSError as e :
                  if e . errno != errno . EEXIST :
                      raise EnvironmentError (  "Cache directory '%s' does not exist "  "and could not be created'" % self . _dir )
      def _key_to_file ( self , key , version = None ) :
 key = self . make_key ( key , version = version )
 self . validate_key ( key )
 return os . path . join ( self . _dir , '' . join (  [ hashlib . md5 ( force_bytes ( key ) ) . hexdigest ( ) , self . cache_suffix ] ) )
   def clear ( self ) :
 if not os . path . exists ( self . _dir ) :
              return
  for fname in self . _list_cache_files ( ) :
              self . _delete ( fname )
    def _is_expired ( self , f ) :
 exp = pickle . load ( f )
 if exp is not None and exp < time . time ( ) :
              f . close ( )
 self . _delete ( f . name )
 return True
  return False
   def _list_cache_files ( self ) :
 if not os . path . exists ( self . _dir ) :
              return [ ]
  filelist = [ os . path . join ( self . _dir , fname ) for fname  in glob . glob1 ( self . _dir , '*%s' % self . cache_suffix ) ]
 return filelist
      class CacheClass ( FileBasedCache ) :
      pass
  import time
 try :
      from django . utils . six . moves import cPickle as pickle
  except ImportError :
      import pickle
   from django . core . cache . backends . base import BaseCache , DEFAULT_TIMEOUT
 from django . utils . synch import RWLock
     _caches = { }
 _expire_info = { }
 _locks = { }
   class LocMemCache ( BaseCache ) :
      def __init__ ( self , name , params ) :
          BaseCache . __init__ ( self , params )
 self . _cache = _caches . setdefault ( name , { } )
 self . _expire_info = _expire_info . setdefault ( name , { } )
 self . _lock = _locks . setdefault ( name , RWLock ( ) )
   def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 pickled = pickle . dumps ( value , pickle . HIGHEST_PROTOCOL )
 with self . _lock . writer ( ) :
              if self . _has_expired ( key ) :
                  self . _set ( key , pickled , timeout )
 return True
  return False
    def get ( self , key , default = None , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 pickled = None
 with self . _lock . reader ( ) :
              if not self . _has_expired ( key ) :
                  pickled = self . _cache [ key ]
   if pickled is not None :
              try :
                  return pickle . loads ( pickled )
  except pickle . PickleError :
                  return default
    with self . _lock . writer ( ) :
              try :
                  del self . _cache [ key ]
 del self . _expire_info [ key ]
  except KeyError :
                  pass
  return default
    def _set ( self , key , value , timeout = DEFAULT_TIMEOUT ) :
          if len ( self . _cache ) >= self . _max_entries :
              self . _cull ( )
  self . _cache [ key ] = value
 self . _expire_info [ key ] = self . get_backend_timeout ( timeout )
   def set ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 pickled = pickle . dumps ( value , pickle . HIGHEST_PROTOCOL )
 with self . _lock . writer ( ) :
              self . _set ( key , pickled , timeout )
    def incr ( self , key , delta = 1 , version = None ) :
          value = self . get ( key , version = version )
 if value is None :
              raise ValueError ( "Key '%s' not found" % key )
  new_value = value + delta
 key = self . make_key ( key , version = version )
 pickled = pickle . dumps ( new_value , pickle . HIGHEST_PROTOCOL )
 with self . _lock . writer ( ) :
              self . _cache [ key ] = pickled
  return new_value
   def has_key ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 with self . _lock . reader ( ) :
              if not self . _has_expired ( key ) :
                  return True
    with self . _lock . writer ( ) :
              try :
                  del self . _cache [ key ]
 del self . _expire_info [ key ]
  except KeyError :
                  pass
  return False
    def _has_expired ( self , key ) :
          exp = self . _expire_info . get ( key , - 1 )
 if exp is None or exp > time . time ( ) :
              return False
  return True
   def _cull ( self ) :
          if self . _cull_frequency == 0 :
              self . clear ( )
  else :
              doomed = [ k for ( i , k ) in enumerate ( self . _cache ) if i % self . _cull_frequency == 0 ]
 for k in doomed :
                  self . _delete ( k )
     def _delete ( self , key ) :
          try :
              del self . _cache [ key ]
  except KeyError :
              pass
  try :
              del self . _expire_info [ key ]
  except KeyError :
              pass
    def delete ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . validate_key ( key )
 with self . _lock . writer ( ) :
              self . _delete ( key )
    def clear ( self ) :
          self . _cache . clear ( )
 self . _expire_info . clear ( )
      class CacheClass ( LocMemCache ) :
      pass
  import time
 import pickle
  from django . core . cache . backends . base import BaseCache , DEFAULT_TIMEOUT
 from django . utils import six
 from django . utils . deprecation import RenameMethodsBase , RemovedInDjango19Warning
 from django . utils . encoding import force_str
 from django . utils . functional import cached_property
   class BaseMemcachedCacheMethods ( RenameMethodsBase ) :
      renamed_methods = (  ( '_get_memcache_timeout' , 'get_backend_timeout' , RemovedInDjango19Warning ) ,  )
    class BaseMemcachedCache ( six . with_metaclass ( BaseMemcachedCacheMethods , BaseCache ) ) :
      def __init__ ( self , server , params , library , value_not_found_exception ) :
          super ( BaseMemcachedCache , self ) . __init__ ( params )
 if isinstance ( server , six . string_types ) :
              self . _servers = server . split ( ';' )
  else :
              self . _servers = server
       self . LibraryValueNotFoundException = value_not_found_exception
  self . _lib = library
 self . _options = params . get ( 'OPTIONS' , None )
   @ property
 def _cache ( self ) :
 if getattr ( self , '_client' , None ) is None :
              self . _client = self . _lib . Client ( self . _servers )
   return self . _client
   def get_backend_timeout ( self , timeout = DEFAULT_TIMEOUT ) :
 if timeout == DEFAULT_TIMEOUT :
              timeout = self . default_timeout
   if timeout is None :
               return 0
  elif int ( timeout ) == 0 :
                timeout = - 1
   if timeout > 2592000 :
                    timeout += int ( time . time ( ) )
  return int ( timeout )
   def make_key ( self , key , version = None ) :
           return force_str ( super ( BaseMemcachedCache , self ) . make_key ( key , version ) )
   def add ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 return self . _cache . add ( key , value , self . get_backend_timeout ( timeout ) )
   def get ( self , key , default = None , version = None ) :
          key = self . make_key ( key , version = version )
 val = self . _cache . get ( key )
 if val is None :
              return default
  return val
   def set ( self , key , value , timeout = DEFAULT_TIMEOUT , version = None ) :
          key = self . make_key ( key , version = version )
 self . _cache . set ( key , value , self . get_backend_timeout ( timeout ) )
   def delete ( self , key , version = None ) :
          key = self . make_key ( key , version = version )
 self . _cache . delete ( key )
   def get_many ( self , keys , version = None ) :
          new_keys = [ self . make_key ( x , version = version ) for x in keys ]
 ret = self . _cache . get_multi ( new_keys )
 if ret :
              _ = { }
 m = dict ( zip ( new_keys , keys ) )
 for k , v in ret . items ( ) :
                  _ [ m [ k ] ] = v
  ret = _
  return ret
   def close ( self , ** kwargs ) :
          self . _cache . disconnect_all ( )
   def incr ( self , key , delta = 1 , version = None ) :
          key = self . make_key ( key , version = version )
  if delta < 0 :
              return self . _cache . decr ( key , - delta )
  try :
              val = self . _cache . incr ( key , delta )
       except self . LibraryValueNotFoundException :
              val = None
  if val is None :
              raise ValueError ( "Key '%s' not found" % key )
  return val
   def decr ( self , key , delta = 1 , version = None ) :
          key = self . make_key ( key , version = version )
  if delta < 0 :
              return self . _cache . incr ( key , - delta )
  try :
              val = self . _cache . decr ( key , delta )
       except self . LibraryValueNotFoundException :
              val = None
  if val is None :
              raise ValueError ( "Key '%s' not found" % key )
  return val
   def set_many ( self , data , timeout = DEFAULT_TIMEOUT , version = None ) :
          safe_data = { }
 for key , value in data . items ( ) :
              key = self . make_key ( key , version = version )
 safe_data [ key ] = value
  self . _cache . set_multi ( safe_data , self . get_backend_timeout ( timeout ) )
   def delete_many ( self , keys , version = None ) :
          l = lambda x : self . make_key ( x , version = version )
 self . _cache . delete_multi ( map ( l , keys ) )
   def clear ( self ) :
          self . _cache . flush_all ( )
     class MemcachedCache ( BaseMemcachedCache ) :
 def __init__ ( self , server , params ) :
          import memcache
 super ( MemcachedCache , self ) . __init__ ( server , params ,  library = memcache ,  value_not_found_exception = ValueError )
   @ property
 def _cache ( self ) :
          if getattr ( self , '_client' , None ) is None :
              self . _client = self . _lib . Client ( self . _servers , pickleProtocol = pickle . HIGHEST_PROTOCOL )
  return self . _client
     class PyLibMCCache ( BaseMemcachedCache ) :
 def __init__ ( self , server , params ) :
          import pylibmc
 super ( PyLibMCCache , self ) . __init__ ( server , params ,  library = pylibmc ,  value_not_found_exception = pylibmc . NotFound )
   @ cached_property
 def _cache ( self ) :
          client = self . _lib . Client ( self . _servers )
 if self . _options :
              client . behaviors = self . _options
   return client
from __future__ import unicode_literals
  import hashlib
 from django . utils . encoding import force_bytes
 from django . utils . http import urlquote
  TEMPLATE_FRAGMENT_KEY_TEMPLATE = 'template.cache.%s.%s'
   def make_template_fragment_key ( fragment_name , vary_on = None ) :
      if vary_on is None :
          vary_on = ( )
  key = ':' . join ( urlquote ( var ) for var in vary_on )
 args = hashlib . md5 ( force_bytes ( key ) )
 return TEMPLATE_FRAGMENT_KEY_TEMPLATE % ( fragment_name , args . hexdigest ( ) )
 from __future__ import unicode_literals
  from . messages import ( CheckMessage ,  Debug , Info , Warning , Error , Critical ,  DEBUG , INFO , WARNING , ERROR , CRITICAL )
 from . registry import register , run_checks , tag_exists , Tags
   import django . core . checks . compatibility . django_1_6_0
 import django . core . checks . compatibility . django_1_7_0
 import django . core . checks . model_checks
  __all__ = [  'CheckMessage' ,  'Debug' , 'Info' , 'Warning' , 'Error' , 'Critical' ,  'DEBUG' , 'INFO' , 'WARNING' , 'ERROR' , 'CRITICAL' ,  'register' , 'run_checks' , 'tag_exists' , 'Tags' ,  ]
 from __future__ import unicode_literals
  from django . apps import apps
  from . . import Warning , register , Tags
   @ register ( Tags . compatibility )
 def check_1_6_compatibility ( ** kwargs ) :
      errors = [ ]
 errors . extend ( _check_test_runner ( ** kwargs ) )
 errors . extend ( _check_boolean_field_default_value ( ** kwargs ) )
 return errors
    def _check_test_runner ( app_configs = None , ** kwargs ) :
 from django . conf import settings
            weight = 0
     if not settings . is_overridden ( 'TEST_RUNNER' ) :
            try :
              settings . SITE_ID
 weight += 2
  except AttributeError :
              pass
    try :
              settings . BASE_DIR
  except AttributeError :
              weight += 2
    if settings . is_overridden ( 'TEMPLATE_LOADERS' ) :
              weight += 2
    if settings . is_overridden ( 'MANAGERS' ) :
              weight += 2
     if settings . is_overridden ( 'ADMINS' ) :
              weight += 1
    if 'django.middleware.clickjacking.XFrameOptionsMiddleware' not in set ( settings . MIDDLEWARE_CLASSES ) :
              weight += 1
    if weight >= 6 :
          return [  Warning (  "Some project unittests may not execute as expected." ,  hint = ( "Django 1.6 introduced a new default test runner. It looks like "  "this project was generated using Django 1.5 or earlier. You should "  "ensure your tests are all running & behaving as expected. See "  "https://docs.djangoproject.com/en/dev/releases/1.6/#new-test-runner "  "for more information." ) ,  obj = None ,  id = '1_6.W001' ,  )  ]
  else :
          return [ ]
     def _check_boolean_field_default_value ( app_configs = None , ** kwargs ) :
 from django . db import models
  problem_fields = [  field  for model in apps . get_models ( ** kwargs )  if app_configs is None or model . _meta . app_config in app_configs  for field in model . _meta . local_fields  if isinstance ( field , models . BooleanField ) and not field . has_default ( )  ]
  return [  Warning (  "BooleanField does not have a default value." ,  hint = ( "Django 1.6 changed the default value of BooleanField from False to None. "  "See https://docs.djangoproject.com/en/1.6/ref/models/fields/#booleanfield "  "for more information." ) ,  obj = field ,  id = '1_6.W002' ,  )  for field in problem_fields  ]
from __future__ import unicode_literals
  from . . import Warning , register , Tags
   @ register ( Tags . compatibility )
 def check_1_7_compatibility ( ** kwargs ) :
      errors = [ ]
 errors . extend ( _check_middleware_classes ( ** kwargs ) )
 return errors
    def _check_middleware_classes ( app_configs = None , ** kwargs ) :
 from django . conf import settings
    if not settings . is_overridden ( 'MIDDLEWARE_CLASSES' ) :
          return [  Warning (  "MIDDLEWARE_CLASSES is not set." ,  hint = ( "Django 1.7 changed the global defaults for the MIDDLEWARE_CLASSES. "  "django.contrib.sessions.middleware.SessionMiddleware, "  "django.contrib.auth.middleware.AuthenticationMiddleware, and "  "django.contrib.messages.middleware.MessageMiddleware were removed from the defaults. "  "If your project needs these middleware then you should configure this setting." ) ,  obj = None ,  id = '1_7.W001' ,  )  ]
  else :
          return [ ]
 from __future__ import unicode_literals
  from django . utils . encoding import python_2_unicode_compatible , force_str
    DEBUG = 10
 INFO = 20
 WARNING = 30
 ERROR = 40
 CRITICAL = 50
   @ python_2_unicode_compatible
 class CheckMessage ( object ) :
       def __init__ ( self , level , msg , hint = None , obj = None , id = None ) :
          assert isinstance ( level , int ) , "The first argument should be level."
 self . level = level
 self . msg = msg
 self . hint = hint
 self . obj = obj
 self . id = id
   def __eq__ ( self , other ) :
          return all ( getattr ( self , attr ) == getattr ( other , attr )  for attr in [ 'level' , 'msg' , 'hint' , 'obj' , 'id' ] )
   def __ne__ ( self , other ) :
          return not ( self == other )
   def __str__ ( self ) :
          from django . db import models
  if self . obj is None :
              obj = "?"
  elif isinstance ( self . obj , models . base . ModelBase ) :
                model = self . obj
 app = model . _meta . app_label
 obj = '%s.%s' % ( app , model . _meta . object_name )
  else :
              obj = force_str ( self . obj )
  id = "(%s) " % self . id if self . id else ""
 hint = "\n\tHINT: %s" % self . hint if self . hint else ''
 return "%s: %s%s%s" % ( obj , id , self . msg , hint )
   def __repr__ ( self ) :
          return "<%s: level=%r, msg=%r, hint=%r, obj=%r, id=%r>" % ( self . __class__ . __name__ , self . level , self . msg , self . hint , self . obj , self . id )
   def is_serious ( self ) :
          return self . level >= ERROR
   def is_silenced ( self ) :
          from django . conf import settings
 return self . id in settings . SILENCED_SYSTEM_CHECKS
     class Debug ( CheckMessage ) :
      def __init__ ( self , * args , ** kwargs ) :
          return super ( Debug , self ) . __init__ ( DEBUG , * args , ** kwargs )
     class Info ( CheckMessage ) :
      def __init__ ( self , * args , ** kwargs ) :
          return super ( Info , self ) . __init__ ( INFO , * args , ** kwargs )
     class Warning ( CheckMessage ) :
      def __init__ ( self , * args , ** kwargs ) :
          return super ( Warning , self ) . __init__ ( WARNING , * args , ** kwargs )
     class Error ( CheckMessage ) :
      def __init__ ( self , * args , ** kwargs ) :
          return super ( Error , self ) . __init__ ( ERROR , * args , ** kwargs )
     class Critical ( CheckMessage ) :
      def __init__ ( self , * args , ** kwargs ) :
          return super ( Critical , self ) . __init__ ( CRITICAL , * args , ** kwargs )
 from __future__ import unicode_literals
  from itertools import chain
 import types
  from django . apps import apps
  from . import Error , Tags , register
   @ register ( Tags . models )
 def check_all_models ( app_configs = None , ** kwargs ) :
      errors = [ model . check ( ** kwargs )  for model in apps . get_models ( )  if app_configs is None or model . _meta . app_config in app_configs ]
 return list ( chain ( * errors ) )
    @ register ( Tags . models , Tags . signals )
 def check_model_signals ( app_configs = None , ** kwargs ) :
 from django . db import models
 errors = [ ]
  for name in dir ( models . signals ) :
          obj = getattr ( models . signals , name )
 if isinstance ( obj , models . signals . ModelSignal ) :
              for reference , receivers in obj . unresolved_references . items ( ) :
                  for receiver , _ , _ in receivers :
                        if isinstance ( receiver , types . FunctionType ) :
                          description = "The '%s' function" % receiver . __name__
  else :
                          description = "An instance of the '%s' class" % receiver . __class__ . __name__
  errors . append (  Error (  "%s was connected to the '%s' signal "  "with a lazy reference to the '%s' sender, "  "which has not been installed." % (  description , name , '.' . join ( reference )  ) ,  obj = receiver . __module__ ,  hint = None ,  id = 'signals.E001'  )  )
     return errors
 from __future__ import unicode_literals
  from itertools import chain
  from django . utils . itercompat import is_iterable
   class Tags ( object ) :
 admin = 'admin'
 compatibility = 'compatibility'
 models = 'models'
 signals = 'signals'
    class CheckRegistry ( object ) :
       def __init__ ( self ) :
          self . registered_checks = [ ]
   def register ( self , * tags ) :
  def inner ( check ) :
              check . tags = tags
 if check not in self . registered_checks :
                  self . registered_checks . append ( check )
  return check
   return inner
   def run_checks ( self , app_configs = None , tags = None ) :
 errors = [ ]
 if tags is not None :
              checks = [ check for check in self . registered_checks  if hasattr ( check , 'tags' ) and set ( check . tags ) & set ( tags ) ]
  else :
              checks = self . registered_checks
   for check in checks :
              new_errors = check ( app_configs = app_configs )
 assert is_iterable ( new_errors ) , (  "The function %r did not return a list. All functions registered "  "with the checks registry must return a list." % check )
 errors . extend ( new_errors )
  return errors
   def tag_exists ( self , tag ) :
          return tag in self . tags_available ( )
   def tags_available ( self ) :
          return set ( chain ( * [ check . tags for check in self . registered_checks if hasattr ( check , 'tags' ) ] ) )
     registry = CheckRegistry ( )
 register = registry . register
 run_checks = registry . run_checks
 tag_exists = registry . tag_exists
 from __future__ import unicode_literals
  from django . conf import settings
 from django . middleware . csrf import get_token
 from django . utils import six
 from django . utils . encoding import smart_text
 from django . utils . functional import lazy
   def csrf ( request ) :
 def _get_val ( ) :
          token = get_token ( request )
 if token is None :
                 return 'NOTPROVIDED'
  else :
              return smart_text ( token )
   _get_val = lazy ( _get_val , six . text_type )
  return { 'csrf_token' : _get_val ( ) }
    def debug ( request ) :
 context_extras = { }
 if settings . DEBUG and request . META . get ( 'REMOTE_ADDR' ) in settings . INTERNAL_IPS :
          context_extras [ 'debug' ] = True
 from django . db import connection
 context_extras [ 'sql_queries' ] = connection . queries
  return context_extras
    def i18n ( request ) :
      from django . utils import translation
  context_extras = { }
 context_extras [ 'LANGUAGES' ] = settings . LANGUAGES
 context_extras [ 'LANGUAGE_CODE' ] = translation . get_language ( )
 context_extras [ 'LANGUAGE_BIDI' ] = translation . get_language_bidi ( )
  return context_extras
    def tz ( request ) :
      from django . utils import timezone
  return { 'TIME_ZONE' : timezone . get_current_timezone_name ( ) }
    def static ( request ) :
 return { 'STATIC_URL' : settings . STATIC_URL }
    def media ( request ) :
 return { 'MEDIA_URL' : settings . MEDIA_URL }
    def request ( request ) :
      return { 'request' : request }
 from functools import reduce
 import operator
  from django . utils import six
 from django . utils . encoding import force_text
   class DjangoRuntimeWarning ( RuntimeWarning ) :
      pass
    class AppRegistryNotReady ( Exception ) :
 pass
    class ObjectDoesNotExist ( Exception ) :
 silent_variable_failure = True
    class MultipleObjectsReturned ( Exception ) :
 pass
    class SuspiciousOperation ( Exception ) :
    class SuspiciousMultipartForm ( SuspiciousOperation ) :
 pass
    class SuspiciousFileOperation ( SuspiciousOperation ) :
 pass
    class DisallowedHost ( SuspiciousOperation ) :
 pass
    class DisallowedRedirect ( SuspiciousOperation ) :
 pass
    class PermissionDenied ( Exception ) :
 pass
    class ViewDoesNotExist ( Exception ) :
 pass
    class MiddlewareNotUsed ( Exception ) :
 pass
    class ImproperlyConfigured ( Exception ) :
 pass
    class FieldError ( Exception ) :
 pass
    NON_FIELD_ERRORS = '__all__'
   class ValidationError ( Exception ) :
 def __init__ ( self , message , code = None , params = None ) :
   super ( ValidationError , self ) . __init__ ( message , code , params )
  if isinstance ( message , ValidationError ) :
              if hasattr ( message , 'error_dict' ) :
                  message = message . error_dict
     elif not hasattr ( message , 'message' if six . PY3 else 'code' ) :
                  message = message . error_list
  else :
                  message , code , params = message . message , message . code , message . params
    if isinstance ( message , dict ) :
              self . error_dict = { }
 for field , messages in message . items ( ) :
                  if not isinstance ( messages , ValidationError ) :
                      messages = ValidationError ( messages )
  self . error_dict [ field ] = messages . error_list
    elif isinstance ( message , list ) :
              self . error_list = [ ]
 for message in message :
                   if not isinstance ( message , ValidationError ) :
                      message = ValidationError ( message )
  self . error_list . extend ( message . error_list )
    else :
              self . message = message
 self . code = code
 self . params = params
 self . error_list = [ self ]
    @ property
 def message_dict ( self ) :
            getattr ( self , 'error_dict' )
  return dict ( self )
   @ property
 def messages ( self ) :
          if hasattr ( self , 'error_dict' ) :
              return reduce ( operator . add , dict ( self ) . values ( ) )
  return list ( self )
   def update_error_dict ( self , error_dict ) :
          if hasattr ( self , 'error_dict' ) :
              for field , error_list in self . error_dict . items ( ) :
                  error_dict . setdefault ( field , [ ] ) . extend ( error_list )
   else :
              error_dict . setdefault ( NON_FIELD_ERRORS , [ ] ) . extend ( self . error_list )
  return error_dict
   def __iter__ ( self ) :
          if hasattr ( self , 'error_dict' ) :
              for field , errors in self . error_dict . items ( ) :
                  yield field , list ( ValidationError ( errors ) )
   else :
              for error in self . error_list :
                  message = error . message
 if error . params :
                      message %= error . params
  yield force_text ( message )
     def __str__ ( self ) :
          if hasattr ( self , 'error_dict' ) :
              return repr ( dict ( self ) )
  return repr ( list ( self ) )
   def __repr__ ( self ) :
          return 'ValidationError(%s)' % self
from django . core . files . base import File
  __all__ = [ 'File' ]
from __future__ import unicode_literals
  import os
 from io import BytesIO , StringIO , UnsupportedOperation
  from django . utils . encoding import smart_text
 from django . core . files . utils import FileProxyMixin
 from django . utils import six
 from django . utils . encoding import force_bytes , python_2_unicode_compatible
   @ python_2_unicode_compatible
 class File ( FileProxyMixin ) :
      DEFAULT_CHUNK_SIZE = 64 * 2 ** 10
  def __init__ ( self , file , name = None ) :
          self . file = file
 if name is None :
              name = getattr ( file , 'name' , None )
  self . name = name
 if hasattr ( file , 'mode' ) :
              self . mode = file . mode
    def __str__ ( self ) :
          return smart_text ( self . name or '' )
   def __repr__ ( self ) :
          return "<%s: %s>" % ( self . __class__ . __name__ , self or "None" )
   def __bool__ ( self ) :
          return bool ( self . name )
   def __nonzero__ ( self ) :
          return type ( self ) . __bool__ ( self )
   def __len__ ( self ) :
          return self . size
   def _get_size_from_underlying_file ( self ) :
          if hasattr ( self . file , 'size' ) :
              return self . file . size
  if hasattr ( self . file , 'name' ) :
              try :
                  return os . path . getsize ( self . file . name )
  except ( OSError , TypeError ) :
                  pass
   if hasattr ( self . file , 'tell' ) and hasattr ( self . file , 'seek' ) :
              pos = self . file . tell ( )
 self . file . seek ( 0 , os . SEEK_END )
 size = self . file . tell ( )
 self . file . seek ( pos )
 return size
  raise AttributeError ( "Unable to determine the file's size." )
   def _get_size ( self ) :
          if hasattr ( self , '_size' ) :
              return self . _size
  self . _size = self . _get_size_from_underlying_file ( )
 return self . _size
   def _set_size ( self , size ) :
          self . _size = size
   size = property ( _get_size , _set_size )
  def _get_closed ( self ) :
          return not self . file or self . file . closed
  closed = property ( _get_closed )
  def chunks ( self , chunk_size = None ) :
 if not chunk_size :
              chunk_size = self . DEFAULT_CHUNK_SIZE
   try :
              self . seek ( 0 )
  except ( AttributeError , UnsupportedOperation ) :
              pass
   while True :
              data = self . read ( chunk_size )
 if not data :
                  break
  yield data
    def multiple_chunks ( self , chunk_size = None ) :
 if not chunk_size :
              chunk_size = self . DEFAULT_CHUNK_SIZE
  return self . size > chunk_size
   def __iter__ ( self ) :
           buffer_ = None
 for chunk in self . chunks ( ) :
              chunk_buffer = BytesIO ( chunk )
  for line in chunk_buffer :
                  if buffer_ :
                      line = buffer_ + line
 buffer_ = None
     if line [ - 1 : ] in ( b'\n' , b'\r' ) :
                      yield line
  else :
                      buffer_ = line
     if buffer_ is not None :
              yield buffer_
    def __enter__ ( self ) :
          return self
   def __exit__ ( self , exc_type , exc_value , tb ) :
          self . close ( )
   def open ( self , mode = None ) :
          if not self . closed :
              self . seek ( 0 )
  elif self . name and os . path . exists ( self . name ) :
              self . file = open ( self . name , mode or self . mode )
  else :
              raise ValueError ( "The file cannot be reopened." )
    def close ( self ) :
          self . file . close ( )
     @ python_2_unicode_compatible
 class ContentFile ( File ) :
 def __init__ ( self , content , name = None ) :
          if six . PY3 :
              stream_class = StringIO if isinstance ( content , six . text_type ) else BytesIO
  else :
              stream_class = BytesIO
 content = force_bytes ( content )
  super ( ContentFile , self ) . __init__ ( stream_class ( content ) , name = name )
 self . size = len ( content )
   def __str__ ( self ) :
          return 'Raw content'
   def __bool__ ( self ) :
          return True
   def __nonzero__ ( self ) :
          return type ( self ) . __bool__ ( self )
   def open ( self , mode = None ) :
          self . seek ( 0 )
   def close ( self ) :
          pass
 import zlib
  from django . core . files import File
   class ImageFile ( File ) :
 def _get_width ( self ) :
          return self . _get_image_dimensions ( ) [ 0 ]
  width = property ( _get_width )
  def _get_height ( self ) :
          return self . _get_image_dimensions ( ) [ 1 ]
  height = property ( _get_height )
  def _get_image_dimensions ( self ) :
          if not hasattr ( self , '_dimensions_cache' ) :
              close = self . closed
 self . open ( )
 self . _dimensions_cache = get_image_dimensions ( self , close = close )
  return self . _dimensions_cache
     def get_image_dimensions ( file_or_path , close = False ) :
 from PIL import ImageFile as PillowImageFile
  p = PillowImageFile . Parser ( )
 if hasattr ( file_or_path , 'read' ) :
          file = file_or_path
 file_pos = file . tell ( )
 file . seek ( 0 )
  else :
          file = open ( file_or_path , 'rb' )
 close = True
  try :
             chunk_size = 1024
 while 1 :
              data = file . read ( chunk_size )
 if not data :
                  break
  try :
                  p . feed ( data )
  except zlib . error as e :
                    if e . args [ 0 ] . startswith ( "Error -5" ) :
                      pass
  else :
                      raise
   if p . image :
                  return p . image . size
  chunk_size *= 2
  return None
  finally :
          if close :
              file . close ( )
  else :
              file . seek ( file_pos )
 import os
  __all__ = ( 'LOCK_EX' , 'LOCK_SH' , 'LOCK_NB' , 'lock' , 'unlock' )
   def _fd ( f ) :
 return f . fileno ( ) if hasattr ( f , 'fileno' ) else f
    if os . name == 'nt' :
      import msvcrt
 from ctypes import ( sizeof , c_ulong , c_void_p , c_int64 ,  Structure , Union , POINTER , windll , byref )
 from ctypes . wintypes import BOOL , DWORD , HANDLE
  LOCK_SH = 0
 LOCK_NB = 0x1
 LOCK_EX = 0x2
    if sizeof ( c_ulong ) != sizeof ( c_void_p ) :
          ULONG_PTR = c_int64
  else :
          ULONG_PTR = c_ulong
  PVOID = c_void_p
   class _OFFSET ( Structure ) :
          _fields_ = [  ( 'Offset' , DWORD ) ,  ( 'OffsetHigh' , DWORD ) ]
   class _OFFSET_UNION ( Union ) :
          _anonymous_ = [ '_offset' ]
 _fields_ = [  ( '_offset' , _OFFSET ) ,  ( 'Pointer' , PVOID ) ]
   class OVERLAPPED ( Structure ) :
          _anonymous_ = [ '_offset_union' ]
 _fields_ = [  ( 'Internal' , ULONG_PTR ) ,  ( 'InternalHigh' , ULONG_PTR ) ,  ( '_offset_union' , _OFFSET_UNION ) ,  ( 'hEvent' , HANDLE ) ]
   LPOVERLAPPED = POINTER ( OVERLAPPED )
   LockFileEx = windll . kernel32 . LockFileEx
 LockFileEx . restype = BOOL
 LockFileEx . argtypes = [ HANDLE , DWORD , DWORD , DWORD , DWORD , LPOVERLAPPED ]
 UnlockFileEx = windll . kernel32 . UnlockFileEx
 UnlockFileEx . restype = BOOL
 UnlockFileEx . argtypes = [ HANDLE , DWORD , DWORD , DWORD , LPOVERLAPPED ]
  def lock ( f , flags ) :
          hfile = msvcrt . get_osfhandle ( _fd ( f ) )
 overlapped = OVERLAPPED ( )
 ret = LockFileEx ( hfile , flags , 0 , 0 , 0xFFFF0000 , byref ( overlapped ) )
 return bool ( ret )
   def unlock ( f ) :
          hfile = msvcrt . get_osfhandle ( _fd ( f ) )
 overlapped = OVERLAPPED ( )
 ret = UnlockFileEx ( hfile , 0 , 0 , 0xFFFF0000 , byref ( overlapped ) )
 return bool ( ret )
   else :
      try :
          import fcntl
 LOCK_SH = fcntl . LOCK_SH
 LOCK_NB = fcntl . LOCK_NB
 LOCK_EX = fcntl . LOCK_EX
  except ( ImportError , AttributeError ) :
           LOCK_EX = LOCK_SH = LOCK_NB = 0
   def lock ( f , flags ) :
               return False
   def unlock ( f ) :
               return True
   else :
          def lock ( f , flags ) :
              ret = fcntl . flock ( _fd ( f ) , flags )
 return ( ret == 0 )
   def unlock ( f ) :
              ret = fcntl . flock ( _fd ( f ) , fcntl . LOCK_UN )
 return ( ret == 0 )
  import os
 from django . core . files import locks
  try :
      from shutil import copystat
  except ImportError :
      import stat
  def copystat ( src , dst ) :
 st = os . stat ( src )
 mode = stat . S_IMODE ( st . st_mode )
 if hasattr ( os , 'utime' ) :
              os . utime ( dst , ( st . st_atime , st . st_mtime ) )
  if hasattr ( os , 'chmod' ) :
              os . chmod ( dst , mode )
     __all__ = [ 'file_move_safe' ]
   def _samefile ( src , dst ) :
       if hasattr ( os . path , 'samefile' ) :
          try :
              return os . path . samefile ( src , dst )
  except OSError :
              return False
     return ( os . path . normcase ( os . path . abspath ( src ) ) ==  os . path . normcase ( os . path . abspath ( dst ) ) )
    def file_move_safe ( old_file_name , new_file_name , chunk_size = 1024 * 64 , allow_overwrite = False ) :
   if _samefile ( old_file_name , new_file_name ) :
          return
   try :
           if not allow_overwrite and os . access ( new_file_name , os . F_OK ) :
              raise IOError ( "Destination file %s exists and allow_overwrite is False" % new_file_name )
   os . rename ( old_file_name , new_file_name )
 return
  except OSError :
            pass
    with open ( old_file_name , 'rb' ) as old_file :
           fd = os . open ( new_file_name , ( os . O_WRONLY | os . O_CREAT | getattr ( os , 'O_BINARY' , 0 ) |  ( os . O_EXCL if not allow_overwrite else 0 ) ) )
 try :
              locks . lock ( fd , locks . LOCK_EX )
 current_chunk = None
 while current_chunk != b'' :
                  current_chunk = old_file . read ( chunk_size )
 os . write ( fd , current_chunk )
   finally :
              locks . unlock ( fd )
 os . close ( fd )
   copystat ( old_file_name , new_file_name )
  try :
          os . remove ( old_file_name )
  except OSError as e :
              if getattr ( e , 'winerror' , 0 ) != 32 and getattr ( e , 'errno' , 0 ) != 13 :
              raise
import os
 import errno
 import itertools
 from datetime import datetime
  from django . conf import settings
 from django . core . exceptions import SuspiciousFileOperation
 from django . core . files import locks , File
 from django . core . files . move import file_move_safe
 from django . utils . encoding import force_text , filepath_to_uri
 from django . utils . functional import LazyObject
 from django . utils . module_loading import import_string
 from django . utils . six . moves . urllib . parse import urljoin
 from django . utils . text import get_valid_filename
 from django . utils . _os import safe_join , abspathu
 from django . utils . deconstruct import deconstructible
   __all__ = ( 'Storage' , 'FileSystemStorage' , 'DefaultStorage' , 'default_storage' )
   class Storage ( object ) :
     def open ( self , name , mode = 'rb' ) :
 return self . _open ( name , mode )
   def save ( self , name , content ) :
  if name is None :
              name = content . name
   if not hasattr ( content , 'chunks' ) :
              content = File ( content )
   name = self . get_available_name ( name )
 name = self . _save ( name , content )
   return force_text ( name . replace ( '\\' , '/' ) )
     def get_valid_name ( self , name ) :
 return get_valid_filename ( name )
   def get_available_name ( self , name ) :
 dir_name , file_name = os . path . split ( name )
 file_root , file_ext = os . path . splitext ( file_name )
    count = itertools . count ( 1 )
 while self . exists ( name ) :
               name = os . path . join ( dir_name , "%s_%s%s" % ( file_root , next ( count ) , file_ext ) )
   return name
   def path ( self , name ) :
 raise NotImplementedError ( "This backend doesn't support absolute paths." )
      def delete ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide a delete() method' )
   def exists ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide an exists() method' )
   def listdir ( self , path ) :
 raise NotImplementedError ( 'subclasses of Storage must provide a listdir() method' )
   def size ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide a size() method' )
   def url ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide a url() method' )
   def accessed_time ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide an accessed_time() method' )
   def created_time ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide a created_time() method' )
   def modified_time ( self , name ) :
 raise NotImplementedError ( 'subclasses of Storage must provide a modified_time() method' )
     @ deconstructible
 class FileSystemStorage ( Storage ) :
  def __init__ ( self , location = None , base_url = None , file_permissions_mode = None ,  directory_permissions_mode = None ) :
          if location is None :
              location = settings . MEDIA_ROOT
  self . base_location = location
 self . location = abspathu ( self . base_location )
 if base_url is None :
              base_url = settings . MEDIA_URL
  elif not base_url . endswith ( '/' ) :
              base_url += '/'
  self . base_url = base_url
 self . file_permissions_mode = (  file_permissions_mode if file_permissions_mode is not None  else settings . FILE_UPLOAD_PERMISSIONS  )
 self . directory_permissions_mode = (  directory_permissions_mode if directory_permissions_mode is not None  else settings . FILE_UPLOAD_DIRECTORY_PERMISSIONS  )
   def _open ( self , name , mode = 'rb' ) :
          return File ( open ( self . path ( name ) , mode ) )
   def _save ( self , name , content ) :
          full_path = self . path ( name )
      directory = os . path . dirname ( full_path )
 if not os . path . exists ( directory ) :
              try :
                  if self . directory_permissions_mode is not None :
                        old_umask = os . umask ( 0 )
 try :
                          os . makedirs ( directory , self . directory_permissions_mode )
  finally :
                          os . umask ( old_umask )
   else :
                      os . makedirs ( directory )
   except OSError as e :
                  if e . errno != errno . EEXIST :
                      raise
    if not os . path . isdir ( directory ) :
              raise IOError ( "%s exists and is not a directory." % directory )
         while True :
              try :
                   if hasattr ( content , 'temporary_file_path' ) :
                      file_move_safe ( content . temporary_file_path ( ) , full_path )
    else :
                        flags = ( os . O_WRONLY | os . O_CREAT | os . O_EXCL |  getattr ( os , 'O_BINARY' , 0 ) )
  fd = os . open ( full_path , flags , 0o666 )
 _file = None
 try :
                          locks . lock ( fd , locks . LOCK_EX )
 for chunk in content . chunks ( ) :
                              if _file is None :
                                  mode = 'wb' if isinstance ( chunk , bytes ) else 'wt'
 _file = os . fdopen ( fd , mode )
  _file . write ( chunk )
   finally :
                          locks . unlock ( fd )
 if _file is not None :
                              _file . close ( )
  else :
                              os . close ( fd )
     except OSError as e :
                  if e . errno == errno . EEXIST :
                       name = self . get_available_name ( name )
 full_path = self . path ( name )
  else :
                      raise
   else :
                   break
    if self . file_permissions_mode is not None :
              os . chmod ( full_path , self . file_permissions_mode )
   return name
   def delete ( self , name ) :
          assert name , "The name argument is not allowed to be empty."
 name = self . path ( name )
     if os . path . exists ( name ) :
              try :
                  os . remove ( name )
  except OSError as e :
                  if e . errno != errno . ENOENT :
                      raise
      def exists ( self , name ) :
          return os . path . exists ( self . path ( name ) )
   def listdir ( self , path ) :
          path = self . path ( path )
 directories , files = [ ] , [ ]
 for entry in os . listdir ( path ) :
              if os . path . isdir ( os . path . join ( path , entry ) ) :
                  directories . append ( entry )
  else :
                  files . append ( entry )
   return directories , files
   def path ( self , name ) :
          try :
              path = safe_join ( self . location , name )
  except ValueError :
              raise SuspiciousFileOperation ( "Attempted access to '%s' denied." % name )
  return os . path . normpath ( path )
   def size ( self , name ) :
          return os . path . getsize ( self . path ( name ) )
   def url ( self , name ) :
          if self . base_url is None :
              raise ValueError ( "This file is not accessible via a URL." )
  return urljoin ( self . base_url , filepath_to_uri ( name ) )
   def accessed_time ( self , name ) :
          return datetime . fromtimestamp ( os . path . getatime ( self . path ( name ) ) )
   def created_time ( self , name ) :
          return datetime . fromtimestamp ( os . path . getctime ( self . path ( name ) ) )
   def modified_time ( self , name ) :
          return datetime . fromtimestamp ( os . path . getmtime ( self . path ( name ) ) )
     def get_storage_class ( import_path = None ) :
      return import_string ( import_path or settings . DEFAULT_FILE_STORAGE )
    class DefaultStorage ( LazyObject ) :
      def _setup ( self ) :
          self . _wrapped = get_storage_class ( ) ( )
    default_storage = DefaultStorage ( )
  import os
 import tempfile
 from django . core . files . utils import FileProxyMixin
  __all__ = ( 'NamedTemporaryFile' , 'gettempdir' , )
   if os . name == 'nt' :
      class TemporaryFile ( FileProxyMixin ) :
 def __init__ ( self , mode = 'w+b' , bufsize = - 1 , suffix = '' , prefix = '' ,  dir = None ) :
              fd , name = tempfile . mkstemp ( suffix = suffix , prefix = prefix , dir = dir )
 self . name = name
 self . file = os . fdopen ( fd , mode , bufsize )
 self . close_called = False
      unlink = os . unlink
  def close ( self ) :
              if not self . close_called :
                  self . close_called = True
 try :
                      self . file . close ( )
  except ( OSError , IOError ) :
                      pass
  try :
                      self . unlink ( self . name )
  except ( OSError ) :
                      pass
     @ property
 def closed ( self ) :
 return self . file . closed
   def __del__ ( self ) :
              self . close ( )
   def __enter__ ( self ) :
              self . file . __enter__ ( )
 return self
   def __exit__ ( self , exc , value , tb ) :
              self . file . __exit__ ( exc , value , tb )
    NamedTemporaryFile = TemporaryFile
  else :
      NamedTemporaryFile = tempfile . NamedTemporaryFile
   gettempdir = tempfile . gettempdir
  import errno
 import os
 from io import BytesIO
  from django . conf import settings
 from django . core . files . base import File
 from django . core . files import temp as tempfile
 from django . utils . encoding import force_str
  __all__ = ( 'UploadedFile' , 'TemporaryUploadedFile' , 'InMemoryUploadedFile' ,  'SimpleUploadedFile' )
   class UploadedFile ( File ) :
 DEFAULT_CHUNK_SIZE = 64 * 2 ** 10
  def __init__ ( self , file = None , name = None , content_type = None , size = None , charset = None , content_type_extra = None ) :
          super ( UploadedFile , self ) . __init__ ( file , name )
 self . size = size
 self . content_type = content_type
 self . charset = charset
 self . content_type_extra = content_type_extra
   def __repr__ ( self ) :
          return force_str ( "<%s: %s (%s)>" % (  self . __class__ . __name__ , self . name , self . content_type ) )
   def _get_name ( self ) :
          return self . _name
   def _set_name ( self , name ) :
           if name is not None :
               name = os . path . basename ( name )
   if len ( name ) > 255 :
                  name , ext = os . path . splitext ( name )
 ext = ext [ : 255 ]
 name = name [ : 255 - len ( ext ) ] + ext
    self . _name = name
   name = property ( _get_name , _set_name )
    class TemporaryUploadedFile ( UploadedFile ) :
 def __init__ ( self , name , content_type , size , charset , content_type_extra = None ) :
          if settings . FILE_UPLOAD_TEMP_DIR :
              file = tempfile . NamedTemporaryFile ( suffix = '.upload' ,  dir = settings . FILE_UPLOAD_TEMP_DIR )
  else :
              file = tempfile . NamedTemporaryFile ( suffix = '.upload' )
  super ( TemporaryUploadedFile , self ) . __init__ ( file , name , content_type , size , charset , content_type_extra )
   def temporary_file_path ( self ) :
 return self . file . name
   def close ( self ) :
          try :
              return self . file . close ( )
  except OSError as e :
              if e . errno != errno . ENOENT :
                     raise
       class InMemoryUploadedFile ( UploadedFile ) :
 def __init__ ( self , file , field_name , name , content_type , size , charset , content_type_extra = None ) :
          super ( InMemoryUploadedFile , self ) . __init__ ( file , name , content_type , size , charset , content_type_extra )
 self . field_name = field_name
   def open ( self , mode = None ) :
          self . file . seek ( 0 )
   def chunks ( self , chunk_size = None ) :
          self . file . seek ( 0 )
 yield self . read ( )
   def multiple_chunks ( self , chunk_size = None ) :
           return False
     class SimpleUploadedFile ( InMemoryUploadedFile ) :
 def __init__ ( self , name , content , content_type = 'text/plain' ) :
          content = content or b''
 super ( SimpleUploadedFile , self ) . __init__ ( BytesIO ( content ) , None , name ,  content_type , len ( content ) , None , None )
   @ classmethod
 def from_dict ( cls , file_dict ) :
 return cls ( file_dict [ 'filename' ] ,  file_dict [ 'content' ] ,  file_dict . get ( 'content-type' , 'text/plain' ) )
  from __future__ import unicode_literals
  from io import BytesIO
  from django . conf import settings
 from django . core . files . uploadedfile import TemporaryUploadedFile , InMemoryUploadedFile
 from django . utils . encoding import python_2_unicode_compatible
 from django . utils . module_loading import import_string
  __all__ = [  'UploadFileException' , 'StopUpload' , 'SkipFile' , 'FileUploadHandler' ,  'TemporaryFileUploadHandler' , 'MemoryFileUploadHandler' , 'load_handler' ,  'StopFutureHandlers'  ]
   class UploadFileException ( Exception ) :
 pass
    @ python_2_unicode_compatible
 class StopUpload ( UploadFileException ) :
 def __init__ ( self , connection_reset = False ) :
 self . connection_reset = connection_reset
   def __str__ ( self ) :
          if self . connection_reset :
              return 'StopUpload: Halt current upload.'
  else :
              return 'StopUpload: Consume request data, then halt.'
      class SkipFile ( UploadFileException ) :
 pass
    class StopFutureHandlers ( UploadFileException ) :
 pass
    class FileUploadHandler ( object ) :
 chunk_size = 64 * 2 ** 10
  def __init__ ( self , request = None ) :
          self . file_name = None
 self . content_type = None
 self . content_length = None
 self . charset = None
 self . content_type_extra = None
 self . request = request
   def handle_raw_input ( self , input_data , META , content_length , boundary , encoding = None ) :
 pass
   def new_file ( self , field_name , file_name , content_type , content_length , charset = None , content_type_extra = None ) :
 self . field_name = field_name
 self . file_name = file_name
 self . content_type = content_type
 self . content_length = content_length
 self . charset = charset
 self . content_type_extra = content_type_extra
   def receive_data_chunk ( self , raw_data , start ) :
 raise NotImplementedError ( 'subclasses of FileUploadHandler must provide a receive_data_chunk() method' )
   def file_complete ( self , file_size ) :
 raise NotImplementedError ( 'subclasses of FileUploadHandler must provide a file_complete() method' )
   def upload_complete ( self ) :
 pass
     class TemporaryFileUploadHandler ( FileUploadHandler ) :
 def __init__ ( self , * args , ** kwargs ) :
          super ( TemporaryFileUploadHandler , self ) . __init__ ( * args , ** kwargs )
   def new_file ( self , file_name , * args , ** kwargs ) :
 super ( TemporaryFileUploadHandler , self ) . new_file ( file_name , * args , ** kwargs )
 self . file = TemporaryUploadedFile ( self . file_name , self . content_type , 0 , self . charset , self . content_type_extra )
   def receive_data_chunk ( self , raw_data , start ) :
          self . file . write ( raw_data )
   def file_complete ( self , file_size ) :
          self . file . seek ( 0 )
 self . file . size = file_size
 return self . file
     class MemoryFileUploadHandler ( FileUploadHandler ) :
  def handle_raw_input ( self , input_data , META , content_length , boundary , encoding = None ) :
   if content_length > settings . FILE_UPLOAD_MAX_MEMORY_SIZE :
              self . activated = False
  else :
              self . activated = True
    def new_file ( self , * args , ** kwargs ) :
          super ( MemoryFileUploadHandler , self ) . new_file ( * args , ** kwargs )
 if self . activated :
              self . file = BytesIO ( )
 raise StopFutureHandlers ( )
    def receive_data_chunk ( self , raw_data , start ) :
 if self . activated :
              self . file . write ( raw_data )
  else :
              return raw_data
    def file_complete ( self , file_size ) :
 if not self . activated :
              return
   self . file . seek ( 0 )
 return InMemoryUploadedFile (  file = self . file ,  field_name = self . field_name ,  name = self . file_name ,  content_type = self . content_type ,  size = file_size ,  charset = self . charset ,  content_type_extra = self . content_type_extra  )
      def load_handler ( path , * args , ** kwargs ) :
 return import_string ( path ) ( * args , ** kwargs )
class FileProxyMixin ( object ) :
  encoding = property ( lambda self : self . file . encoding )
 fileno = property ( lambda self : self . file . fileno )
 flush = property ( lambda self : self . file . flush )
 isatty = property ( lambda self : self . file . isatty )
 newlines = property ( lambda self : self . file . newlines )
 read = property ( lambda self : self . file . read )
 readinto = property ( lambda self : self . file . readinto )
 readline = property ( lambda self : self . file . readline )
 readlines = property ( lambda self : self . file . readlines )
 seek = property ( lambda self : self . file . seek )
 softspace = property ( lambda self : self . file . softspace )
 tell = property ( lambda self : self . file . tell )
 truncate = property ( lambda self : self . file . truncate )
 write = property ( lambda self : self . file . write )
 writelines = property ( lambda self : self . file . writelines )
 xreadlines = property ( lambda self : self . file . xreadlines )
  def __iter__ ( self ) :
          return iter ( self . file )
from __future__ import unicode_literals
  import logging
 import sys
 import types
  from django import http
 from django . conf import settings
 from django . core import urlresolvers
 from django . core import signals
 from django . core . exceptions import MiddlewareNotUsed , PermissionDenied , SuspiciousOperation
 from django . db import connections , transaction
 from django . utils . encoding import force_text
 from django . utils . module_loading import import_string
 from django . utils import six
 from django . views import debug
  logger = logging . getLogger ( 'django.request' )
   class BaseHandler ( object ) :
       response_fixes = [  http . fix_location_header ,  http . conditional_content_removal ,  ]
  def __init__ ( self ) :
          self . _request_middleware = self . _view_middleware = self . _template_response_middleware = self . _response_middleware = self . _exception_middleware = None
   def load_middleware ( self ) :
 self . _view_middleware = [ ]
 self . _template_response_middleware = [ ]
 self . _response_middleware = [ ]
 self . _exception_middleware = [ ]
  request_middleware = [ ]
 for middleware_path in settings . MIDDLEWARE_CLASSES :
              mw_class = import_string ( middleware_path )
 try :
                  mw_instance = mw_class ( )
  except MiddlewareNotUsed :
                  continue
   if hasattr ( mw_instance , 'process_request' ) :
                  request_middleware . append ( mw_instance . process_request )
  if hasattr ( mw_instance , 'process_view' ) :
                  self . _view_middleware . append ( mw_instance . process_view )
  if hasattr ( mw_instance , 'process_template_response' ) :
                  self . _template_response_middleware . insert ( 0 , mw_instance . process_template_response )
  if hasattr ( mw_instance , 'process_response' ) :
                  self . _response_middleware . insert ( 0 , mw_instance . process_response )
  if hasattr ( mw_instance , 'process_exception' ) :
                  self . _exception_middleware . insert ( 0 , mw_instance . process_exception )
      self . _request_middleware = request_middleware
   def make_view_atomic ( self , view ) :
          non_atomic_requests = getattr ( view , '_non_atomic_requests' , set ( ) )
 for db in connections . all ( ) :
              if ( db . settings_dict [ 'ATOMIC_REQUESTS' ]  and db . alias not in non_atomic_requests ) :
                  view = transaction . atomic ( using = db . alias ) ( view )
   return view
   def get_exception_response ( self , request , resolver , status_code ) :
          try :
              callback , param_dict = resolver . resolve_error_handler ( status_code )
 response = callback ( request , ** param_dict )
  except :
              signals . got_request_exception . send ( sender = self . __class__ , request = request )
 response = self . handle_uncaught_exception ( request , resolver , sys . exc_info ( ) )
   return response
   def get_response ( self , request ) :
      urlconf = settings . ROOT_URLCONF
 urlresolvers . set_urlconf ( urlconf )
 resolver = urlresolvers . RegexURLResolver ( r'^/' , urlconf )
 try :
              response = None
  for middleware_method in self . _request_middleware :
                  response = middleware_method ( request )
 if response :
                      break
    if response is None :
                  if hasattr ( request , 'urlconf' ) :
                       urlconf = request . urlconf
 urlresolvers . set_urlconf ( urlconf )
 resolver = urlresolvers . RegexURLResolver ( r'^/' , urlconf )
   resolver_match = resolver . resolve ( request . path_info )
 callback , callback_args , callback_kwargs = resolver_match
 request . resolver_match = resolver_match
   for middleware_method in self . _view_middleware :
                      response = middleware_method ( request , callback , callback_args , callback_kwargs )
 if response :
                          break
     if response is None :
                  wrapped_callback = self . make_view_atomic ( callback )
 try :
                      response = wrapped_callback ( request , * callback_args , ** callback_kwargs )
  except Exception as e :
                         for middleware_method in self . _exception_middleware :
                          response = middleware_method ( request , e )
 if response :
                              break
   if response is None :
                          raise
      if response is None :
                  if isinstance ( callback , types . FunctionType ) :
                      view_name = callback . __name__
  else :
                      view_name = callback . __class__ . __name__ + '.__call__'
  raise ValueError ( "The view %s.%s didn't return an HttpResponse object. It returned None instead."  % ( callback . __module__ , view_name ) )
     if hasattr ( response , 'render' ) and callable ( response . render ) :
                  for middleware_method in self . _template_response_middleware :
                      response = middleware_method ( request , response )
  if response is None :
                          raise ValueError (  "%s.process_template_response didn't return an "  "HttpResponse object. It returned None instead."  % ( middleware_method . __self__ . __class__ . __name__ ) )
   response = response . render ( )
    except http . Http404 as e :
              logger . warning ( 'Not Found: %s' , request . path ,  extra = {  'status_code' : 404 ,  'request' : request  } )
 if settings . DEBUG :
                  response = debug . technical_404_response ( request , e )
  else :
                  response = self . get_exception_response ( request , resolver , 404 )
    except PermissionDenied :
              logger . warning (  'Forbidden (Permission denied): %s' , request . path ,  extra = {  'status_code' : 403 ,  'request' : request  } )
 response = self . get_exception_response ( request , resolver , 403 )
   except SuspiciousOperation as e :
                security_logger = logging . getLogger ( 'django.security.%s' %  e . __class__ . __name__ )
 security_logger . error (  force_text ( e ) ,  extra = {  'status_code' : 400 ,  'request' : request  } )
 if settings . DEBUG :
                  return debug . technical_500_response ( request , * sys . exc_info ( ) , status_code = 400 )
   response = self . get_exception_response ( request , resolver , 400 )
   except SystemExit :
               raise
   except :
               signals . got_request_exception . send ( sender = self . __class__ , request = request )
 response = self . handle_uncaught_exception ( request , resolver , sys . exc_info ( ) )
   try :
               for middleware_method in self . _response_middleware :
                  response = middleware_method ( request , response )
  if response is None :
                      raise ValueError (  "%s.process_response didn't return an "  "HttpResponse object. It returned None instead."  % ( middleware_method . __self__ . __class__ . __name__ ) )
   response = self . apply_response_fixes ( request , response )
  except :
              signals . got_request_exception . send ( sender = self . __class__ , request = request )
 response = self . handle_uncaught_exception ( request , resolver , sys . exc_info ( ) )
   response . _closable_objects . append ( request )
  return response
   def handle_uncaught_exception ( self , request , resolver , exc_info ) :
 if settings . DEBUG_PROPAGATE_EXCEPTIONS :
              raise
   logger . error ( 'Internal Server Error: %s' , request . path ,  exc_info = exc_info ,  extra = {  'status_code' : 500 ,  'request' : request  }  )
  if settings . DEBUG :
              return debug . technical_500_response ( request , * exc_info )
    if resolver . urlconf_module is None :
              six . reraise ( * exc_info )
   callback , param_dict = resolver . resolve_error_handler ( 500 )
 return callback ( request , ** param_dict )
   def apply_response_fixes ( self , request , response ) :
 for func in self . response_fixes :
              response = func ( request , response )
  return response
from __future__ import unicode_literals
  import cgi
 import codecs
 import logging
 import sys
 from io import BytesIO
 from threading import Lock
 import warnings
  from django import http
 from django . conf import settings
 from django . core import signals
 from django . core . handlers import base
 from django . core . urlresolvers import set_script_prefix
 from django . utils import datastructures
 from django . utils . deprecation import RemovedInDjango19Warning
 from django . utils . encoding import force_str , force_text
 from django . utils . functional import cached_property
 from django . utils import six
   from django . http . response import REASON_PHRASES as STATUS_CODE_TEXT
  logger = logging . getLogger ( 'django.request' )